{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c1eda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import imgrvt as rvt\n",
    "import pims\n",
    "import trackpy as tp\n",
    "import pandas as pd\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels \\\n",
    "    import RBF, WhiteKernel\n",
    "from matplotlib.patches import Circle\n",
    "%config InlineBackend.figure_format='retina'\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_widths\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial']\n",
    "plt.rc('xtick', labelsize=8)      # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=8)      # fontsize of the tick labels \n",
    "from sympy import *\n",
    "cmap = matplotlib.colormaps['viridis']\n",
    "cmap\n",
    "from colormath.color_objects import XYZColor, sRGBColor\n",
    "from colormath.color_conversions import convert_color\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import time\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from scipy.interpolate import CubicSpline\n",
    "tab10 = plt.get_cmap(\"tab10\")\n",
    "viridis = plt.get_cmap(\"viridis\")\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "from scipy.interpolate import LSQUnivariateSpline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71658f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the green channel of the RGB image\n",
    "@pims.pipeline\n",
    "def gray(image):\n",
    "    return image[:, :, 1]\n",
    "\n",
    "# read all the images corresponding to different time points at a specific location within the capillary\n",
    "frames = gray(pims.open('/*.png'))\n",
    "Lt = len(frames)\n",
    "frames[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544c0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203a0c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(src, results, titles=None): # plot several images to compare different RVT (radial variance transform) parameters\n",
    "    nres=len(results)\n",
    "    _,axes=plt.subplots(1,nres+1,figsize=(4*nres+4,3))\n",
    "    axes[0].imshow(src,cmap=\"gray\")\n",
    "    axes[0].set_title(\"Source\")\n",
    "    for ax,res,t in zip(axes[1:],results,titles or [None]*nres):\n",
    "        ax.imshow(res,cmap=\"inferno\")\n",
    "        if t:\n",
    "            ax.set_title(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754c5e91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ly,Lx = frames[0].shape\n",
    "start = 45\n",
    "xsize = 2080\n",
    "ysize = 1552\n",
    "xmin = 0\n",
    "ymin = 0\n",
    "img = frames[start][ymin:ymin+ysize, xmin:xmin+xsize]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77841c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmin = 30\n",
    "rmax = 150\n",
    "highpass_size = 1\n",
    "kind = 'normalized'\n",
    "img_rvt = rvt.rvt(img, rmin=rmin, rmax=rmax, highpass_size=highpass_size, kind=kind)\n",
    "plot_comparison(img, [img_rvt], [\"RVT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ebeed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rvt)\n",
    "plt.colorbar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a0ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 3\n",
    "separation = 50\n",
    "f = tp.locate(img_rvt, diameter, preprocess=False, separation=separation)\n",
    "tp.annotate(f, img, plot_style={'marker':'.','markersize':4});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 16;\n",
    "range = (0,1.6)\n",
    "plt.hist(f['mass'], bins = n_bins, range = range, rwidth = 0.9)\n",
    "plt.xlabel('mass');\n",
    "plt.ylabel('count');\n",
    "\n",
    "\n",
    "plt.ylim(0,100)\n",
    "plt.xticks(fontsize=14);\n",
    "plt.yticks(fontsize=14);\n",
    "plt.hist(img_rvt, n_bins, range = range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee2f0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "diameter = 3\n",
    "minmass = 0.1\n",
    "separation = 50\n",
    "f = tp.locate(img_rvt, diameter, preprocess=False, minmass=minmass, separation=separation) #topn = 20\n",
    "tp.annotate(f, img, plot_style={'marker':'.','markersize':4});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86a9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb46313",
   "metadata": {},
   "source": [
    "# Process Video (all Drops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44306b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1722afc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters for the RVT function\n",
    "rmin = 30\n",
    "rmax = 90\n",
    "highpass_size = 1\n",
    "kind = 'normalized'\n",
    "diameter = 3\n",
    "minmass = 0.1\n",
    "separation = 50\n",
    "wsize = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaea5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only adds outputs of rvt.rvt fucntion that identifies drop centers to rvt.imgs folder \n",
    "imgs = []\n",
    "rvt_imgs = []\n",
    "finish = len(frames)\n",
    "for frame in frames[start:stop]:\n",
    "    img = frame[ymin:ymin+ysize, xmin:xmin+xsize]\n",
    "    rvt_img = rvt.rvt(img, rmin=rmin, rmax=rmax, highpass_size=highpass_size, kind=kind)\n",
    "    imgs.append(img)\n",
    "    rvt_imgs.append(rvt_img)\n",
    "    if len(rvt_imgs)%50==0:\n",
    "        print(len(rvt_imgs))\n",
    "        \n",
    "# % is Modulo Operator - divides LHS by RHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae30b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rvt_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88b01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracks drops centers for all images present in rvt.imgs\n",
    "df_tp_batch = tp.batch(rvt_imgs, diameter, preprocess=False, minmass=minmass, separation=separation)\n",
    "df_tp_batch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba16db3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# link particles using tp.link_df\n",
    "linked_droplets = tp.link_df(df_tp_batch, search_range=70, memory=3)\n",
    "\n",
    "# search_rangefloat or tuple the maximum distance features can move between frames, optionally per dimension\n",
    "# memoryinteger, optional - the maximum number of frames during which a feature can vanish, then reappear nearby, and be considered the same particle. 0 by default.\n",
    "\n",
    "# remove drops near the edge\n",
    "idx = (linked_droplets['x'] >= wsize ) & (linked_droplets['x'] < xsize - wsize - 2) & (linked_droplets['y'] >= wsize) & (linked_droplets['y'] < ysize - wsize - 2)\n",
    "linked_droplets = linked_droplets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904ba7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = tp.plot_traj(linked_droplets, label=True, superimpose=imgs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06554d35",
   "metadata": {},
   "source": [
    "# Radius calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47de56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_drop_size3(img, row, wsize, theta = 1, sigma = 5):\n",
    "    # identify drop\n",
    "    yc = int(np.round(row['y'])) # drop center pixel accuracy\n",
    "    xc = int(np.round(row['x'])) \n",
    "    dy = row['y'] - yc\n",
    "    dx = row['x'] - xc\n",
    "    \n",
    "    if (yc - wsize < 0) or (yc + wsize + 1 >= ysize) or (xc - wsize < 0) or (xc + wsize + 1 >= xsize):\n",
    "        return np.nan\n",
    "    \n",
    "    # make a window\n",
    "    yw = np.arange(-wsize, wsize + 1) - dy\n",
    "    xw = np.arange(-wsize, wsize + 1) - dx\n",
    "    rw = np.ndarray.flatten(np.sqrt(yw[:, None]**2 + xw[None, :]**2))\n",
    "    iw = np.ndarray.flatten(img[yc - wsize:yc + wsize + 1, xc - wsize:xc + wsize + 1])\n",
    "    \n",
    "    num_of_knots = 30\n",
    "    knot_positions = np.linspace(3, wsize, num_of_knots)\n",
    "\n",
    "    # Performe the spline fitting (degree=k)\n",
    "    isort = np.argsort(rw)\n",
    "    spline = LSQUnivariateSpline(rw[isort], iw[isort], knot_positions, k=5)\n",
    "\n",
    "    # Calculate second derivative at multiple points\n",
    "    r_eval = np.linspace(3, wsize, 1000)  # Evaluate over the entire range\n",
    "    spline_second_derivative = spline.derivative(2)\n",
    "    second_derivative_values = spline_second_derivative(r_eval)\n",
    "\n",
    "    # Find sign changes in the second derivative\n",
    "    sign_changes = np.where(np.diff(np.sign(second_derivative_values)))[0]\n",
    "\n",
    "    # Calculate the derivative of the spline at the inflection points\n",
    "    inflection_points = r_eval[sign_changes]\n",
    "    spline_derivative_values = spline.derivative()(inflection_points)\n",
    "\n",
    "    # Find the inflection point with the maximum positive slope\n",
    "    max_positive_slope_index = np.argmax(spline_derivative_values)\n",
    "    rmax2 = inflection_points[max_positive_slope_index]\n",
    "    imax2 = spline(rmax2)\n",
    "    \n",
    "    radius = rmax2\n",
    "        \n",
    "    return radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23910d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'frame' column to integers in final_droplets DataFrame\n",
    "linked_droplets['frame'] = linked_droplets['frame'].astype(int)\n",
    "\n",
    "# Iterate through each unique particle\n",
    "for particle in linked_droplets['particle'].unique():\n",
    "    idx = (linked_droplets['particle'] == particle)\n",
    "    print('particle=', particle)\n",
    "    \n",
    "    # Iterate through the rows for the current particle\n",
    "    for index, row in linked_droplets[idx].iterrows():\n",
    "        # Ensure the 'frame' value is an integer\n",
    "        frame_index = int(row['frame'])\n",
    "        print('frame = ', frame_index)\n",
    "        wsize = 120\n",
    "            \n",
    "        #checkpoint\n",
    "            \n",
    "        if frame_index > 1:\n",
    "            frame_2 = frame_index - 1\n",
    "            index_2 = (linked_droplets['particle']==particle) & (linked_droplets['frame']==frame_2)\n",
    "            #radius of particle in the previous frame\n",
    "            radius_2 = linked_droplets[index_2]['radius'].values\n",
    "            checkpoint = (wsize - 1)/pixel_per_micron\n",
    "            if radius_2 > checkpoint:\n",
    "                wsize = 150  \n",
    "                print('changed wsize', wsize)\n",
    "            \n",
    "        radius = calc_drop_size3(imgs[frame_index], row, wsize)\n",
    "\n",
    "        # Check for NaN values in the radius calculation\n",
    "        if not np.isnan(radius):\n",
    "            # Convert radius to microns\n",
    "            pixel_per_micron = 6.76\n",
    "            radius_microns = radius / pixel_per_micron\n",
    "\n",
    "            # Update 'radius' column for the current row\n",
    "            linked_droplets.at[index, 'radius'] = radius_microns\n",
    "\n",
    "            # Print progress\n",
    "            print(f\"Particle {particle}, Radius: {radius_microns}\")\n",
    "\n",
    "# Check the resulting DataFrame with updated radius values\n",
    "print(linked_droplets.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c6ba0b",
   "metadata": {},
   "source": [
    "# only consider the drops that appear in frame 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09a6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "particles_in_frame_0 = linked_droplets[linked_droplets['frame'] == 0]['particle'].unique()\n",
    "final_droplets = linked_droplets[linked_droplets['particle'].isin(particles_in_frame_0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d103a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the data by particle ID and count the number of frames each particle appears in after filtering\n",
    "frame0_counts = final_droplets.groupby('particle')['frame'].nunique()\n",
    "frame0counts = pd.DataFrame(frame0_counts)\n",
    "frame0counts.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c76e376",
   "metadata": {},
   "source": [
    "# signal and vacoule detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c44de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload csv file/dataframe generated above that contains the pixel location and radius of each drop present in frame 0\n",
    "final_droplets = pd.read_csv('.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89856807",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 0\n",
    "stop = 99\n",
    "frame_nos = np.arange(start, stop + 1)\n",
    "\n",
    "all_vsignals = []\n",
    "\n",
    "particles = final_droplets['particle'].unique()\n",
    "\n",
    "for particle in particles:\n",
    "    vsignals = []  # initialize the signals list for the current particle\n",
    "    print(\"Processing particle:\", particle)\n",
    "    \n",
    "    for frame in frame_nos:\n",
    "        #frame_v2 = frame + 500\n",
    "        idx = (final_droplets['frame'] == frame) & (final_droplets['particle'] == particle)\n",
    "        img = frames[frame][ymin:ymin + ysize, xmin:xmin + xsize]\n",
    "        radius = final_droplets[idx]['radius'].values * 6.76\n",
    "        if not len(radius) == 0:                                                                      \n",
    "            print(\"Processing frame:\", frame)\n",
    "\n",
    "            wsize = radius * 1.2\n",
    "            wsize = int(wsize)\n",
    "\n",
    "            yc = final_droplets['y'].values[idx]\n",
    "            xc = final_droplets['x'].values[idx]\n",
    "\n",
    "            ycPix = int(yc)\n",
    "            xcPix = int(xc)\n",
    "\n",
    "            xPix = np.arange(-wsize, wsize)\n",
    "            yPix = np.arange(-wsize, wsize + 1)\n",
    "            rPix = np.sqrt((xPix[:, None] + xc - xcPix) ** 2 + (yPix[None, :] + yc - ycPix) ** 2)\n",
    "            thetaPix = np.arctan2(yPix[None, :] + yc - ycPix, xPix[:, None] + xc - xcPix)\n",
    "\n",
    "            rMax = int(wsize / np.sqrt(2)) # rMax is 85% of the radius\n",
    "            rBins = np.arange(2, rMax + 1)\n",
    "            means = np.zeros((rMax - 1,))\n",
    "            variances = np.zeros((rMax - 1,))\n",
    "            counts = np.zeros((rMax - 1,))\n",
    "            params = np.zeros((rMax - 1, 7))\n",
    "            cropped = img[ycPix - wsize:ycPix + wsize, xcPix - wsize:xcPix + wsize + 1]\n",
    "                \n",
    "            for i, r in enumerate(rBins):\n",
    "                index = (rPix > r) & (rPix < r + 1) # concentric circle\n",
    "                intensities = np.array(cropped[index])\n",
    "\n",
    "                # calculate variances and means\n",
    "                counts[i] = intensities.shape[0]\n",
    "                means[i] = np.mean(intensities)\n",
    "                variances[i] = np.var(intensities)\n",
    "\n",
    "                # fit harmonic functions\n",
    "                X = np.column_stack((thetaPix[index] ** 0, np.cos(thetaPix[index]), np.sin(thetaPix[index]),\n",
    "                                    np.cos(2 * thetaPix[index]), np.sin(2 * thetaPix[index]),\n",
    "                                    np.cos(3 * thetaPix[index]), np.sin(3 * thetaPix[index])))\n",
    "                params[i, :] = np.linalg.lstsq(X, intensities, rcond=None)[0]\n",
    "\n",
    "            vsignal = np.sum(counts * (params[:, 5] ** 2 + params[:, 6] ** 2) / np.sqrt(np.pi)) / np.sum(counts)\n",
    "            #all_vsignals.append(vsignal)\n",
    "            final_droplets.loc[idx, 'vsignal'] = vsignal\n",
    "            print('visgnal=', radius)\n",
    "        #else:\n",
    "            #vsignals.append(np.nan)\n",
    "    #final_droplets.loc[idx, 'vsignal'] = np.nan\n",
    "            \n",
    "    print(f\"Particle {particle}, Frame {frame}: Signal = {vsignal}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b6a390",
   "metadata": {},
   "source": [
    "## plot vsignal of a single drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baee823",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "particle = 14\n",
    "mask = final_droplets['particle'] == particle\n",
    "data = final_droplets[mask]\n",
    "plt.plot(data['frame'], data['vsignal'], '-o', label=f'Particle {particle}')\n",
    "plt.xlim(0,135)\n",
    "\n",
    "plt.axhline(y=1.2)\n",
    "plt.xlabel('frame', fontsize = 14)\n",
    "plt.ylabel('vsignal', fontsize = 14)\n",
    "plt.legend(loc='upper left', bbox_to_anchor=(1, 1))\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a2cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_droplets['vacuole'] = np.where(final_droplets['vsignal'] > 1.2, 'yes', 'no')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6264605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_droplets.to_csv('.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa1b97",
   "metadata": {},
   "source": [
    "## Detect the beginning of vacuole formation in drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc3405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload csv file/dataframe generated above that contains the pixel location, radius and angular variance of each drop \n",
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f9d4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter particles with 'vacuole' = 'yes' for more than 3 frames\n",
    "particle_vacuole_counts = df[df['vacuole'] == 'yes'].groupby('particle').size()\n",
    "qualified_particles = particle_vacuole_counts[particle_vacuole_counts >= 3].index\n",
    "\n",
    "# filter the original df based on selected particles\n",
    "filtered_df = df[df['particle'].isin(qualified_particles)]\n",
    "\n",
    "# find the first occurrence of vsignal > 1.2 for each qualified particle\n",
    "particle_no = []\n",
    "first_vsignal = []\n",
    "pH_values = []\n",
    "dpHdt_values = []\n",
    "radius_values = []\n",
    "\n",
    "for particle in qualified_particles:\n",
    "    particle_data = filtered_df[(filtered_df['particle'] == particle) & (filtered_df['vsignal'] > 1.2)]\n",
    "    if not particle_data.empty:\n",
    "        particle_no.append(particle_data['particle'].iloc[0])\n",
    "        \n",
    "        first_vsignal.append(particle_data['vsignal'].iloc[0])\n",
    "        \n",
    "        pH_values.append(particle_data['pH'].iloc[0])\n",
    "        \n",
    "        dpHdt_values.append(particle_data['dpH/dt'].iloc[0])\n",
    "        \n",
    "        radius_values.append(particle_data['radius'].iloc[0])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.scatter(pH_values, radius_values, label='Particles')\n",
    "\n",
    "\n",
    "plt.xlabel('pH')\n",
    "plt.ylabel('radius')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070f0076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the list with NaN to match the length of the DataFrame\n",
    "particle_no_v2 = particle_no + [np.nan] * (len(df) - len(first_vsignal))\n",
    "\n",
    "# Add a new column named 'particle_vfirst' with the values from the padded list\n",
    "df['particle_vfirst'] = particle_no_v2\n",
    "\n",
    "pH_values_v2 = pH_values + [np.nan] * (len(df) - len(first_vsignal))\n",
    "df['pH_vfirst'] = pH_values_v2\n",
    "\n",
    "dpHdt_values_v2 = dpHdt_values + [np.nan] * (len(df) - len(first_vsignal))\n",
    "df['dpHdt_vfirst'] = dpHdt_values_v2\n",
    "\n",
    "first_vsignal_v2 = first_vsignal + [np.nan] * (len(df) - len(first_vsignal))\n",
    "df['vfirst'] = first_vsignal_v2\n",
    "\n",
    "radius_values_v2 = radius_values + [np.nan] * (len(df) - len(first_vsignal))\n",
    "df['radius_vfirst'] = radius_values_v2\n",
    "\n",
    "\n",
    "# Save the DataFrame back to the CSV file\n",
    "df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
